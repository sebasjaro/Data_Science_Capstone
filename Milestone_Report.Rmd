---
title: 'Data Science Capstone: Milestone Report'
author: "Sebastian Jaroszewicz"
date: "10/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This is the Milestone Report for the Coursera Data Science Capstone Project.The goal of the capstone project is to create a predictive text model using a large text corpus of documents as training data. Natural language processing techniques will be used to perform the analysis and build the predictive model.
The objective of this report is to preprocess the data, perform an exploratory data analysis and summarize the main features of the training data. The dataset was provided by SwiftKey.

## Getting the Data
Download, unzip and load the data. The data is downloaded from https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip

```{r data}
#Verify that the data has not been previously downloaded, download and unzip
url <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
file_name <- "Coursera-SwiftKey.zip"
if (!file.exists(file_name)) {
  download.file(url,file_name)
  unzip(file_name)
}

# read the data
file_b <- file("final/en_US/en_US.blogs.txt","rb")
blogs <- readLines(file_b, encoding = "UTF-8", skipNul = TRUE)
close(file_b)

file_n <- file("final/en_US/en_US.news.txt","rb")
news <- readLines(file_n, encoding = "UTF-8", skipNul = TRUE)
close(file_n)

file_t <- file("final/en_US/en_US.twitter.txt","rb")
twitter <- readLines(file_t, encoding = "UTF-8", skipNul = TRUE)
close(file_t)
```

## Data Summary

```{r summary}
library(stringi)
library(kableExtra)

# Files sizes
files <- c("final/en_US/en_US.blogs.txt","final/en_US/en_US.news.txt","final/en_US/en_US.twitter.txt")
file_names <- c("Blogs","News","Twitter")
file_sizes <- file.info(files)$size/1024^2

# Number of lines per file
n_lines <- c(length(blogs),length(news),length(twitter))
n_words <- c(sum(stri_count_words(blogs)), sum(stri_count_words(news)), sum(stri_count_words(twitter)))
summary_df <- data.frame(File = file_names, Size = file_sizes, Lines = n_lines, Words = n_words)
#kable(summary_df)
summary_df %>% 
        kbl() %>%
        kable_paper(bootstrap_options = "striped", full_width = F)
```

## Sampling
As can be seen in the table above, the sets are very large. Due to this we will carry out a sampling of the data in order to improve the performance of the analysis. We will randomly choose 1% of each data set to demonstrate data preprocessing and exploratory data analysis.

```{r sampling}
set.seed(31415)
percent <- .01
sample_blogs <- sample(blogs, length(blogs) * percent)
sample_news <- sample(news, length(news) * percent)
sample_twitter <- sample(twitter, length(twitter) * percent)
sample <- c(sample_blogs, sample_news, sample_twitter)
lines_sample <- length(sample)
words_sample <- sum(stri_count_words(sample))
```
The number of lines in the data sample is `r toString(lines_sample)` and the number of words is `r toString(words_sample)`

## Cleaning and preprocessing the data

